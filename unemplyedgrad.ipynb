{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy8GiRexV68hSVVS9Vi7Wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rutvi1996/RAG-project/blob/main/unemplyedgrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### This notebook demonstrates a sample project to generate cover letters based on job descriptions and candidate's information.\n",
        "    It involves the following steps:\n",
        "    1. Extract text from resumes, cover letters, and project documents.\n",
        "    2. Encode the texts into embeddings using Sentence Transformers.\n",
        "    3. Find relevant texts based on cosine similarity to the job description.\n",
        "    4. Generate a cover letter using GPT-2 based on the relevant texts and job description.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2EgWV2jtD8Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "# Import libraries for PDF and DOCX handling\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "import os\n"
      ],
      "metadata": {
        "id": "zf40bAmz3uyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bfs3UwiS4AjU",
        "outputId": "eafcdf57-b931-4277-c432-75fcd1456b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define functions to extract text from PDF and DOCX files and from a folder\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    doc = Document(docx_path)\n",
        "    text = [paragraph.text for paragraph in doc.paragraphs if paragraph.text]\n",
        "    return '\\n'.join(text)\n",
        "\n",
        "def extract_texts_from_folder(folder_path):\n",
        "    texts = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if filename.endswith('.pdf'):\n",
        "            text = extract_text_from_pdf(file_path)\n",
        "            texts.append(text)\n",
        "        elif filename.endswith('.docx'):\n",
        "            text = extract_text_from_docx(file_path)\n",
        "            texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# Paths to your folders in Google Drive\n",
        "resume_path = '/content/drive/My Drive/RAG cover letter tool/Resumes'\n",
        "cover_letter_path = '/content/drive/My Drive/RAG cover letter tool/Cover Letters'\n",
        "project_path = '/content/drive/My Drive/RAG cover letter tool/Previous projects'\n",
        "\n",
        "# Extract texts\n",
        "resume_texts = extract_texts_from_folder(resume_path)\n",
        "cover_letter_texts = extract_texts_from_folder(cover_letter_path)\n",
        "project_texts = extract_texts_from_folder(project_path)\n"
      ],
      "metadata": {
        "id": "EAYemhp-4Nb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the sentence-transformers library\n",
        "!pip install sentence-transformers\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D7lYFFpp5of8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sentence transformer model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "sentence_model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\") # Changed model to sentence_model\n",
        "\n",
        "# Define a function to encode texts into embeddings\n",
        "def encode_texts(texts):\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        model_output = sentence_model(**encoded_input)\n",
        "    return model_output.last_hidden_state.mean(dim=1)\n",
        "\n",
        "# Combine all texts and labels\n",
        "all_texts = resume_texts + cover_letter_texts + project_texts\n",
        "labels = ['resume'] * len(resume_texts) + ['cover_letter'] * len(cover_letter_texts) + ['project'] * len(project_texts)\n",
        "\n",
        "# Encode documents\n",
        "documents_embeddings = encode_texts(all_texts)\n"
      ],
      "metadata": {
        "id": "TtJWSFD47jkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to find relevant texts based on cosine similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def find_relevant_texts(query, embeddings, documents, top_n=5):\n",
        "    # Encode the query using the tokenizer and sentence_model\n",
        "    encoded_input = tokenizer([query], padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        query_embedding = sentence_model(**encoded_input).last_hidden_state.mean(dim=1)\n",
        "\n",
        "    cosine_scores = cosine_similarity(query_embedding, embeddings)[0]\n",
        "    top_indices = np.argsort(cosine_scores)[::-1][:top_n]\n",
        "    return [(documents[i], cosine_scores[i]) for i in top_indices]\n"
      ],
      "metadata": {
        "id": "JpP3cBeo8KOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example job description\n",
        "job_description = \"Seeking a data scientist with expertise in machine learning and natural language processing.\"\n",
        "\n",
        "# Find the top 5 relevant texts for the job description\n",
        "relevant_texts = find_relevant_texts(job_description, embeddings, all_texts)\n",
        "for text, score in relevant_texts:\n",
        "    print(f\"Score: {score}\\nText: {text[:500]}...\\n\")  # Print a snippet of each text\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_5A1E2Mt8W6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "# Set environment variable for Hugging Face Transformers\n",
        "import os\n",
        "os.environ[\"HF_HOME\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "S-wvgENK9LXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the text generation model pipeline\n",
        "generator = pipeline('text-generation', model='gpt2', tokenizer='gpt2')  # You can specify the model and tokenizer\n",
        "\n",
        "def generate_cover_letter(context, job_desc):\n",
        "    # Check if context is a string and if not, convert it to a string\n",
        "    if not isinstance(context, str):\n",
        "        context = str(context)\n",
        "\n",
        "    # Truncate the context to a shorter length\n",
        "    max_context_length = 256  # Example: Limit context to 256 tokens\n",
        "    context = context[:max_context_length]\n",
        "\n",
        "    prompt = f\"Context: {context}\\nJob Description: {job_desc}\\n###\\nPlease write a detailed cover letter:\"\n",
        "    results = generator(prompt, max_new_tokens=512, num_return_sequences=1) # Use max_new_tokens instead of max_length\n",
        "    return results[0]['generated_text']\n",
        "\n",
        "# Using the relevant texts as context\n",
        "# Ensure that context is a string by joining the text elements of relevant_texts\n",
        "context = \" \".join([text for text, _ in relevant_texts])  # Concatenate relevant texts to form the context\n",
        "job_description = \"Seeking a data scientist with expertise in machine learning and natural language processing.\"\n",
        "\n",
        "# Generate the cover letter\n",
        "cover_letter = generate_cover_letter(context, job_description)\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "svkcooOo-3B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpvybtnZKDtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}